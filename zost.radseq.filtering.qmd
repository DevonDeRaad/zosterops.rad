---
title: "*Zosterops* RADseq filtering"
format: html
toc: true
toc-title: Document Contents
number-sections: true
embed-resources: true
bibliography: references.bib
---

<iframe src="https://macaulaylibrary.org/asset/173436361/embed" height="500" width="640" frameborder="0" allowfullscreen>

</iframe>

## Load R packages {style="color: pink"}

```{r}
#| output: false
library(vcfR) #v1.14.0
library(ggplot2) #v3.4.1
library(adegenet) #v2.1.10
library(SNPfiltR) #v1.0.1
library(StAMPP) #v1.6.3
```

We will follow the SNP filtering protocol outlined by the [SNPfiltR](https://devonderaad.github.io/SNPfiltR/) R package in [@deraad2022].

## Read in data {style="color: black"}

We will read in the unfiltered SNPs for all samples output as a vcf file after using BWA [@li2009] to map our raw RADseq data to the *Zosterops japonicus* reference genome (available at: <https://www.ncbi.nlm.nih.gov/assembly/GCA_017612475.1>) [@venkatraman2021].

```{r}
#| output: false
#read in vcf
vcfR <- read.vcfR("~/Desktop/cali.zosterops.rad/zost.unfiltered.snps.vcf.gz")
```

```{r}
#check the metadata for the raw, unfiltered SNP dataset
vcfR

#read in sample info csv
sample.info<-read.csv("~/Desktop/cali.zosterops.rad/zosterops.RAD.sampling.csv")

#make sure sampling file matches the samples in your vcf
sample.info$ID == colnames(vcfR@gt)[-1]
```

## Implement quality filters that don't involve missing data

This is because removing low data samples will alter percentage/quantile based missing data cutoffs, so we wait to implement those until after deciding on our final set of samples for downstream analysis

```{r}
#hard filter to minimum depth of 5, and minimum genotype quality of 30
vcfR<-hard_filter(vcfR=vcfR, depth = 3, gq = 30)
```

Use the function `allele_balance()` to filter for allele balance from [Puritz SNP filtering tutorial](http://www.ddocent.com/filtering/) "Allele balance: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous, we expect that the allele balance in our data (for real loci) should be close to 0.5"

```{r}
#execute allele balance filter
vcfR<-filter_allele_balance(vcfR, min.ratio = .10, max.ratio = .90)
```

We now want to implement a max depth filter (super high depth loci are likely multiple loci stuck together into a single paralogous locus, which we want to remove).

```{r}
#visualize and pick appropriate max depth cutoff
max_depth(vcfR)

#filter vcf by the max depth cutoff you chose
vcfR<-max_depth(vcfR, maxdepth = 250)
```

Remove SNPs from the vcfR that have become invariant following the removal of questionable genotypes above, and see how many SNPs we have left after this initial set of filters

```{r}
vcfR<-min_mac(vcfR, min.mac = 1)
vcfR
```

## Setting the missing data by sample threshold

Check out the exploratory visualizations and make decisions about which samples to keep for downstream analysis.

```{r}
#run function to visualize per sample missingness
miss<-missing_by_sample(vcfR)
```

```{r}
#run function to visualize per SNP missingness
by.snp<-missing_by_snp(vcfR)
```

Based on these visualizations, we will want to drop the worst sequenced samples that are dragging down the rest of the dataset. Drop those samples based on an approximate missing data proportion cutoff here (this can always be revised if we end up feeling like this is too lenient or stringent later):

```{r}
#run function to drop samples above the threshold we want from the vcf
vcfR.trim<-missing_by_sample(vcfR=vcfR, cutoff = .9)
#remove invariant sites generated by sample trimming
vcfR.trim<-min_mac(vcfR.trim, min.mac = 1)
```

## Setting the missing data by SNP threshold

Now we will visualize different per SNP missing data thresholds and identify a value that optimizes the trade-off between amount of missing data and the total number of SNPs retained.

```{r}
#see what effect trimming samples had on missing data across the dataset
by.snp<-missing_by_snp(vcfR.trim)
#we want to identify the three samples that don't seem to improve much, even as we crank up the missingness per SNP threshold (i.e., the ones lagging out to the right in this plot)
#to do so, we will get an updated list of missingness per sample across a variety of thresholds saved as a dataframe named 'miss'
miss<-missing_by_sample(vcfR.trim)
#to identify those lagging samples, we will isolate the part of the dataframe corresponing to a 90% completeness per SNP filter, where a handful of samples are clearly lagging
m<-miss[miss$filt == 0.9,]
#print the 10 samples with the lowest number of SNPs retained at a 90% per SNP completeness threshold
m[order(m$snps.retained)[1:10],]
#we can now easily remove remaining problematic samples directly with this simple code:
vcfR.trim<-vcfR.trim[,colnames(vcfR.trim@gt) != "ZpalDOT-5746" & colnames(vcfR.trim@gt) != "Zmon27152" & colnames(vcfR.trim@gt) != "ZJsi003" & colnames(vcfR.trim@gt) != "ZJlo010" & colnames(vcfR.trim@gt) != "ZERxx003" & colnames(vcfR.trim@gt) != "ZJja011"]
#drop any SNPs that became invariant because of sample removal
vcfR.trim<-min_mac(vcfR.trim, min.mac = 1)
#see what effect trimming samples had on missing data across the dataset
by.snp<-missing_by_snp(vcfR.trim)
```

Visualize sample relatedness at 99% per-SNP completeness cutoff to see our null expectations if there is no missing data effect

```{r}
#set 99% completeness per SNP threshold
test<-missing_by_snp(vcfR.trim, cutoff=.99)
missing_by_sample(test) #no samples above 8% missing data
#convert to genlight
gen<-vcfR2genlight(test)
#assign populations (a StaMPP requirement)
gen@pop<-as.factor(gen@ind.names)
#generate pairwise divergence matrix
sample.div <- stamppNeisD(gen, pop = FALSE)
#export for splitstree
stamppPhylip(distance.mat=sample.div, file="~/Desktop/cali.zosterops.rad/test.99.splits.txt")
```

![99% complete splitstree](images/Screenshot%202023-04-13%20at%205.06.44%20PM.png)

![99% completeness threshold shows that samples 'Zpxx002' and 'ZJsi027' are really intermediate, not just weakly assigned due to excess missing data.](images/Screenshot%202023-04-13%20at%205.08.08%20PM-01.png)

Try setting the threshold at 90% (should retain around 15K high quality SNPs)

```{r}
vcfR.trimmed<-missing_by_snp(vcfR=vcfR.trim, cutoff = .9)
miss<-missing_by_sample(vcfR.trimmed)
vcfR.trimmed
#convert to genlight
gen<-vcfR2genlight(vcfR.trimmed)
#assign populations (a StaMPP requirement)
gen@pop<-as.factor(gen@ind.names)
#generate pairwise divergence matrix
sample.div <- stamppNeisD(gen, pop = FALSE)
#export for splitstree
stamppPhylip(distance.mat=sample.div, file="~/Desktop/cali.zosterops.rad/filtered.90.splits.txt")
```

![Now with a greater number of SNPs (15K vs 1K) we can parse fine-scale geographic structure in *Z. japonicus*. Our intermediate samples show up in the same places and the relationships between clades stay the same, indicating that we can safely set this 90% completeness threshold, allowing \~5% missing genotypes into the matrix, without biasing our estimates of relatedness between samples.](images/Screenshot%202023-04-13%20at%205.28.15%20PM-01.png)

## Remove overlapping SNPs
It is a known thing (see [this](https://groups.google.com/g/stacks-users/c/Ag8YyEFe7z0)) that Stacks will not merge SNPs called twice if they are sequenced by separate (but physically overlapping) loci. To account for this, we will simply remove a SNP every time its chromosome and position have already been seen in the dataset with the following code:
```{r}
#generate dataframe containing information for chromosome and bp locality of each SNP
df<-as.data.frame(vcfR.trimmed@fix[,1:2])
#calc number of duplicated SNPs to remove
nrow(df) - length(unique(paste(df$CHROM,df$POS)))
#remove duplicated SNPs
vcfR.trimmed<-vcfR.trimmed[!duplicated(paste(df$CHROM,df$POS)),]
```

## Visualize depth and quality across all retained genotypes

```{r}
#plot depth per snp and per sample
dp <- extract.gt(vcfR.trimmed, element = "DP", as.numeric=TRUE)
heatmap.bp(dp, rlabels = FALSE)

#plot genotype quality per snp and per sample
gq <- extract.gt(vcfR.trimmed, element = "GQ", as.numeric=TRUE)
heatmap.bp(gq, rlabels = FALSE)
```

## linkage filter
Now filter for linkage

```{r}
#perform linkage filtering to get a reduced vcf with only unlinked SNPs
vcfR.thin<-distance_thin(vcfR.trimmed, min.distance = 1000)
```

## write vcf to disk for downstream analyses

```{r}
#get info for all SNPs passing filtering vcf dataset
vcfR.trimmed
#write to disk
#vcfR::write.vcf(vcfR.trimmed, file = "~/Desktop/cali.zosterops.rad/filtered.snps.vcf.gz")

#get info for the thinned SNP dataset
vcfR.thin
#write to disk
#vcfR::write.vcf(vcfR.thin, file = "~/Desktop/cali.zosterops.rad/filtered.unlinked.snps.vcf.gz")
```
